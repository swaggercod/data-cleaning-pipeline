# E-Commerce Data Cleaning Pipeline

A comprehensive Python-based data cleaning pipeline for e-commerce datasets, implementing industry-standard data quality practices.

## ğŸ“‹ Project Overview

This project demonstrates end-to-end data cleaning techniques using **Pandas** and **NumPy**. It processes raw e-commerce data with common real-world quality issues and produces a clean, analysis-ready dataset.

## ğŸ¯ Features

- **Column Standardization**: Normalize column names (lowercase, underscore-separated)
- **Missing Value Handling**: Intelligent strategies for null values based on data type
- **Text Normalization**: Standardize text formatting (case, whitespace)
- **Data Validation**: Remove invalid records (negative prices, invalid ratings, etc.)
- **Duplicate Removal**: Identify and remove duplicate rows

## ğŸ—‚ï¸ Project Structure

```
data-cleaning-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw, uncleaned data
â”‚   â”‚   â””â”€â”€ ecommerce_raw_data.csv
â”‚   â””â”€â”€ cleaned/              # Cleaned, processed data
â”‚       â””â”€â”€ ecommerce_cleaned_data.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generate_sample_data.py    # Generate sample dataset
â”‚   â”œâ”€â”€ explore_data.py            # Data exploration script
â”‚   â””â”€â”€ data_cleaner.py            # Main cleaning pipeline
â”œâ”€â”€ notebooks/                # Jupyter notebooks (optional)
â”œâ”€â”€ tests/                    # Unit tests (future)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore               # Git ignore rules
â””â”€â”€ README.md                # This file
```

## ğŸ› ï¸ Technologies Used

- **Python 3.x**
- **Pandas**: Data manipulation and analysis
- **NumPy**: Numerical operations

## ğŸ“¦ Installation

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/data-cleaning-pipeline.git
cd data-cleaning-pipeline
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Generate sample data** (optional)
```bash
python src/generate_sample_data.py
```

## ğŸš€ Usage

### Run the complete pipeline:

```bash
python src/data_cleaner.py
```

### Or use individual functions:

```python
from src.data_cleaner import clean_data_pipeline

# Clean your data
df_cleaned = clean_data_pipeline(
    input_path='data/raw/your_data.csv',
    output_path='data/cleaned/your_data_cleaned.csv'
)
```

## ğŸ“Š Data Cleaning Steps

### 1. **Clean Column Names**
- Convert to lowercase
- Replace spaces with underscores
- Example: `Customer Name` â†’ `customer_name`

### 2. **Handle Missing Values**
| Column Type | Strategy | Reason |
|------------|----------|--------|
| Numerical (price, quantity) | Fill with **median** | Not affected by outliers |
| Categorical (category) | Fill with **mode** | Most frequent value |
| Critical (email, date) | **Drop rows** | Essential fields |
| Customer name | Fill with 'Unknown' | Preserve records |

### 3. **Normalize Text**
- Strip leading/trailing whitespace
- Standardize case (Title case for names, lowercase for categories)
- Example: `"ELECTRONICS"` â†’ `"electronics"`

### 4. **Remove Invalid Data**
- **Price**: Remove if â‰¤ 0
- **Quantity**: Remove if â‰¤ 0
- **Rating**: Keep only 1-5 range
- **Email**: Remove if missing '@' symbol

### 5. **Remove Duplicates**
- Identify duplicate rows
- Keep first occurrence
- Remove subsequent duplicates

## ğŸ“ˆ Results

**Before Cleaning:**
- 1,050 rows
- 662 missing values
- 45+ duplicate rows
- Invalid data (negative prices, invalid ratings)
- Inconsistent text formatting

**After Cleaning:**
- ~628 clean rows
- 0 missing values âœ…
- 0 duplicates âœ…
- 0 invalid records âœ…
- Standardized formatting âœ…

## ğŸ“ Example

```python
import pandas as pd
from src.data_cleaner import (
    clean_column_names,
    handle_missing_values,
    normalize_text_columns,
    remove_invalid_data,
    remove_duplicates
)

# Load data
df = pd.read_csv('data/raw/ecommerce_raw_data.csv')

# Apply cleaning steps
df = clean_column_names(df)
df = handle_missing_values(df)
df = normalize_text_columns(df)
df = remove_invalid_data(df)
df = remove_duplicates(df)

# Save cleaned data
df.to_csv('data/cleaned/output.csv', index=False)
```

## ğŸ§ª Testing

Run the test suite:

```bash
python src/data_cleaner.py
```

This will execute all cleaning functions and display detailed logs.

## ğŸ“ Learning Outcomes

This project demonstrates:
- âœ… Pandas data manipulation techniques
- âœ… Handling missing data strategies
- âœ… Data validation and quality checks
- âœ… Text processing and normalization
- âœ… Duplicate detection and removal
- âœ… Writing clean, documented Python code
- âœ… Project structure best practices

## ğŸ”® Future Enhancements

- [ ] Add unit tests with pytest
- [ ] Implement data profiling reports
- [ ] Add date parsing and validation
- [ ] Create interactive dashboard with Streamlit
- [ ] Add logging functionality
- [ ] Support for multiple file formats (Excel, JSON)
- [ ] Automated data quality scoring

## ğŸ‘¤ Author

**Your Name**
- GitHub: [@swaggercod](https://github.com/swaggercod)
- LinkedIn: [yusuf-ozturk](https://www.linkedin.com/in/yusuf-ozturk-561880367/)

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ™ Acknowledgments

- Sample data generation inspired by real-world e-commerce datasets
- Built as a learning project for data engineering fundamentals

---

â­ **If you find this project helpful, please give it a star!** â­
